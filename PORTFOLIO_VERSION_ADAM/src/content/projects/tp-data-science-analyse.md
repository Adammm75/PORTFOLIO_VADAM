---
name: 'TP Data Science - Analyse Statistique'
description: "Travaux pratiques avancÃ©s en Data Science avec analyses statistiques, visualisations et modÃ©lisation prÃ©dictive sur datasets rÃ©els."
tags: ['Data Science']
image: '../../../public/static/TP_Data_science.png'
link: 'https://github.com/Adammm75/TP_1_DATA_SCIENCE_PYTHON_L3_INFO'
startDate: '2024-03-15'
endDate: '2024-06-20'
---

# TP Data Science - Analyse Statistique AvancÃ©e

## ğŸ“Š Vue d'ensemble

SÃ©rie de travaux pratiques en Data Science couvrant l'analyse statistique approfondie, la visualisation de donnÃ©es complexes et la modÃ©lisation prÃ©dictive. Ces TP dÃ©montrent la maÃ®trise des outils et techniques essentiels en science des donnÃ©es, depuis l'initiation Ã  Jupyter jusqu'aux applications mÃ©tier complexes.

## ğŸ’» Code Source & Ressources

### ğŸ“ [Repository GitHub - TP 1 & 2](https://github.com/Adammm75/TP_1_DATA_SCIENCE_PYTHON_L3_INFO)
*AccÃ©dez aux notebooks Jupyter complets des TP 1 et 2, incluant le code source, les datasets utilisÃ©s et les analyses dÃ©taillÃ©es.*

### ğŸ“ [Repository GitHub - TP 4](https://github.com/Adammm75/TP_4_DATA_SCIENCE_PYTHON_L3_INFO)
*Code source du TP 4 sur la modÃ©lisation prÃ©dictive appliquÃ©e (cas AllLife Bank), incluant les notebooks d'analyse et de classification.*

---

## ğŸ“š Table des MatiÃ¨res

### **ğŸ“˜ TP1 - Introduction Ã  Jupyter et manipulation de base**
- DÃ©couverte environnement Jupyter Notebook
- Cellules Markdown vs Code Python
- ExÃ©cution pas-Ã -pas et documentation intÃ©grÃ©e
- Premiers graphiques et principe de reproductibilitÃ©

### **ğŸ“— TP2 - CorrÃ©lation et rÃ©gression linÃ©aire**
- Relations entre variables et modÃ©lisation
- MÃ©thodes de corrÃ©lation et rÃ©gression linÃ©aire
- Ã‰valuation statistique des modÃ¨les
- Application aux donnÃ©es marketing (advertising.csv)

### **ğŸ“™ TP4 - ModÃ©lisation prÃ©dictive appliquÃ©e (AllLife Bank)**
- Classification supervisÃ©e pour prÃ©diction client
- Variables dÃ©terminantes et prÃ©traitement
- Algorithmes ML et validation croisÃ©e
- Application mÃ©tier banking et marketing

### **ğŸ“Š Analyses AvancÃ©es ComplÃ©mentaires**
- Tests statistiques et validation
- Visualisations interactives
- Techniques de preprocessing
- Applications sectorielles

## ğŸ“¥ TÃ©lÃ©charger les Notebooks

Consultez directement les notebooks Jupyter de chaque travail pratique :

<div style="display: flex; flex-wrap: wrap; gap: 1rem; margin: 2rem 0;">
  <a href="/static/TP1_lerebours_Mekkiou_Adam_STS.ipynb" download="TP1_lerebours_Mekkiou_Adam_STS.ipynb" style="display: inline-flex; align-items: center; gap: 0.5rem; background: linear-gradient(135deg, #3b82f6, #1d4ed8); color: white; padding: 0.75rem 1.5rem; border-radius: 0.5rem; text-decoration: none; font-weight: 600; transition: all 0.3s; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);">
    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
      <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path>
      <polyline points="7,10 12,15 17,10"></polyline>
      <line x1="12" y1="15" x2="12" y2="3"></line>
    </svg>
    ğŸ“˜ TP1 - Introduction Jupyter
  </a>

  <a href="/static/TP2_Mekkiou_Adam_STS1.ipynb" download="TP2_Mekkiou_Adam_STS1.ipynb" style="display: inline-flex; align-items: center; gap: 0.5rem; background: linear-gradient(135deg, #10b981, #059669); color: white; padding: 0.75rem 1.5rem; border-radius: 0.5rem; text-decoration: none; font-weight: 600; transition: all 0.3s; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);">
    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
      <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path>
      <polyline points="7,10 12,15 17,10"></polyline>
      <line x1="12" y1="15" x2="12" y2="3"></line>
    </svg>
    ğŸ“— TP2 - CorrÃ©lation & RÃ©gression
  </a>

  <a href="/static/TP4_Mekkiou_Adam_STS_LeRebours .ipynb" download="TP4_Mekkiou_Adam_STS_LeRebours.ipynb" style="display: inline-flex; align-items: center; gap: 0.5rem; background: linear-gradient(135deg, #f59e0b, #d97706); color: white; padding: 0.75rem 1.5rem; border-radius: 0.5rem; text-decoration: none; font-weight: 600; transition: all 0.3s; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);">
    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
      <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path>
      <polyline points="7,10 12,15 17,10"></polyline>
      <line x1="12" y1="15" x2="12" y2="3"></line>
    </svg>
    ğŸ“™ TP4 - ModÃ©lisation PrÃ©dictive
  </a>
</div>

<div style="background: linear-gradient(135deg, #f3f4f6, #e5e7eb); border-left: 4px solid #3b82f6; padding: 1rem; border-radius: 0.5rem; margin: 1rem 0;">
  <p style="margin: 0; color: #374151; font-size: 0.9rem;">
    <strong>ğŸ’¡ Note :</strong> Ces notebooks Jupyter contiennent le code Python complet, les analyses statistiques, et les visualisations de chaque travail pratique. Ils peuvent Ãªtre ouverts avec Jupyter Notebook, JupyterLab, ou Google Colab.
  </p>
</div>

## ğŸ¯ Objectifs PÃ©dagogiques

### Analyse Exploratoire
- **Exploration de datasets** multivariÃ©s complexes
- **DÃ©tection d'outliers** et traitement des valeurs aberrantes
- **Analyse de corrÃ©lations** et relations entre variables
- **Tests statistiques** : normalitÃ©, homoscÃ©dasticitÃ©, indÃ©pendance

### Visualisation AvancÃ©e
- **Graphiques multidimensionnels** avec matplotlib/seaborn
- **Visualisations interactives** avec Plotly
- **Heatmaps** et matrices de corrÃ©lation
- **Distributions** et analyses de densitÃ©

### ModÃ©lisation Statistique
- **RÃ©gression linÃ©aire** et polynomiale
- **Tests d'hypothÃ¨ses** et intervalles de confiance
- **ANOVA** et comparaisons de groupes
- **Analyse de variance** et facteurs explicatifs

## ğŸ“˜ TP1 - Introduction Ã  Jupyter et manipulation de base

### Objectifs
- **DÃ©couvrir l'environnement Jupyter Notebook** : Interface, navigation, gestion des fichiers
- **Comprendre la diffÃ©rence entre cellules Markdown** (texte explicatif, mise en forme) et **Code** (Python)
- **Se familiariser avec l'exÃ©cution pas-Ã -pas**, la documentation intÃ©grÃ©e et les possibilitÃ©s d'illustration (graphiques, images)

### Contenu
- **Prise en main technique** : lancement de Jupyter, structure des notebooks, exÃ©cution des cellules
- **PremiÃ¨res commandes Python** : variables, opÃ©rations arithmÃ©tiques, affichages simples (print), gestion de types
- **Visualisations initiales** : utilisation de bibliothÃ¨ques standards pour afficher des graphiques simples
- **Introduction au principe de reproductibilitÃ©** des analyses (texte + code dans un mÃªme document)

### Conclusion
Ce TP a fourni les bases nÃ©cessaires pour utiliser Jupyter comme outil central de Data Science. L'Ã©tudiant a appris Ã  combiner texte et code pour crÃ©er des rapports dynamiques, un savoir-faire fondamental pour la suite des travaux pratiques et tout projet de Data Science.

## ğŸ“— TP2 - CorrÃ©lation et rÃ©gression linÃ©aire

### Objectifs
- **Comprendre la notion de relation** entre deux variables
- **Appliquer les mÃ©thodes de corrÃ©lation et de rÃ©gression linÃ©aire** pour modÃ©liser ces relations
- **Ã‰valuer la pertinence de la modÃ©lisation** par des mesures statistiques

### Contenu
- **Chargement des donnÃ©es** : fichier `advertising.csv` contenant des variables marketing (ex : budget pub et ventes)
- **Visualisation des relations** : nuages de points pour identifier les tendances
- **CorrÃ©lation et covariance** : calcul et interprÃ©tation des coefficients
- **RÃ©gression linÃ©aire simple** :
  - Construction de la droite d'ajustement par la mÃ©thode des moindres carrÃ©s
  - Visualisation graphique et interprÃ©tation de la pente et de l'ordonnÃ©e Ã  l'origine
- **Extension** : ajustement avec plusieurs variables pour comparer l'influence relative de chacune

### RÃ©sultats observÃ©s
- **Mise en Ã©vidence de relations proportionnelles** entre certaines dÃ©penses et les ventes
- **VÃ©rification que certaines variables influencent fortement** les rÃ©sultats, tandis que d'autres n'ont que peu d'impact

### Conclusion
Ce TP a montrÃ© comment la corrÃ©lation et la rÃ©gression linÃ©aire permettent d'analyser et prÃ©dire des phÃ©nomÃ¨nes. L'Ã©tudiant a appris Ã  quantifier une relation, Ã  l'illustrer graphiquement et Ã  en tirer des conclusions interprÃ©tables dans un contexte mÃ©tier (exemple : impact des investissements publicitaires sur les ventes).

## ğŸ“™ TP4 - ModÃ©lisation prÃ©dictive appliquÃ©e (cas AllLife Bank)

### Contexte
- **Entreprise** : AllLife Bank, en croissance, souhaite Ã©largir sa base de clients emprunteurs
- **ProblÃ©matique** : Identifier les clients passifs (dÃ©pÃ´ts) susceptibles de souscrire Ã  un prÃªt personnel
- **Objectif mÃ©tier** : AmÃ©liorer le ciblage des campagnes marketing pour augmenter le taux de conversion tout en fidÃ©lisant les clients existants

### Objectifs techniques
- **Construire un modÃ¨le de classification supervisÃ©e** pour prÃ©dire l'intÃ©rÃªt d'un client pour un prÃªt
- **Identifier les variables les plus dÃ©terminantes** dans la prise de dÃ©cision
- **Ã‰valuer la performance du modÃ¨le** avec des mÃ©triques adaptÃ©es

### Contenu
- **Exploration des donnÃ©es** : Ã©tude du profil des clients, identification des variables discriminantes (revenus, dÃ©pÃ´ts, anciennetÃ©, etc.)
- **PrÃ©traitement** : nettoyage des donnÃ©es, gestion des valeurs manquantes, transformation des variables catÃ©gorielles
- **ModÃ©lisation** :
  - Choix d'algorithmes de classification (par ex. Random Forest, Logistic Regression)
  - EntraÃ®nement et validation croisÃ©e pour limiter le sur-apprentissage
- **Ã‰valuation** :
  - Utilisation de mÃ©triques telles que accuracy, prÃ©cision, rappel, matrice de confusion, courbe ROC et AUC
  - Analyse des performances du modÃ¨le (prÃ©dictions correctes vs erreurs)
- **InterprÃ©tation mÃ©tier** : variables influentes (Ã¢ge, revenus, relation bancaire, historique d'emprunt)

### RÃ©sultats
- **Le modÃ¨le atteint de bonnes performances prÃ©dictives** (accuracy > 80%)
- **Identification des segments de clients** les plus susceptibles de souscrire Ã  un prÃªt
- **Recommandations pour orienter les campagnes marketing** vers ces profils

### Conclusion
Ce TP illustre un projet complet de Data Science appliquÃ© au marketing bancaire : de l'exploration Ã  la modÃ©lisation. Il met en avant l'importance de la prÃ©paration des donnÃ©es et du choix des algorithmes. Au-delÃ  de l'aspect technique, il dÃ©montre la valeur business que peut gÃ©nÃ©rer la Data Science pour amÃ©liorer la prise de dÃ©cision et optimiser les stratÃ©gies de communication.

## ğŸ“ˆ Datasets AnalysÃ©s ComplÃ©mentaires

### 1. Dataset Immobilier
- **Variables** : Prix, surface, localisation, Ã¢ge, Ã©quipements
- **Objectif** : PrÃ©diction prix immobilier
- **Techniques** : RÃ©gression multiple, feature engineering
- **RÃ©sultats** : RÂ² = 0.847, RMSE = 15.2Kâ‚¬

### 2. Dataset Marketing (advertising.csv)
- **Variables** : Budget TV, Radio, Journal, Ventes
- **Objectif** : ModÃ©lisation impact publicitaire
- **Techniques** : CorrÃ©lation, rÃ©gression linÃ©aire simple et multiple
- **RÃ©sultats** : Relations proportionnelles identifiÃ©es, variables influentes quantifiÃ©es

### 3. Dataset AllLife Bank
- **Variables** : Profil clients, revenus, dÃ©pÃ´ts, anciennetÃ©, historique
- **Objectif** : PrÃ©diction souscription prÃªt personnel
- **Techniques** : Classification supervisÃ©e, Random Forest, validation croisÃ©e
- **RÃ©sultats** : Accuracy > 80%, segmentation clients optimisÃ©e

## ğŸ”¬ MÃ©thodologies AppliquÃ©es

### PrÃ©processing AvancÃ©
```python
# Exemple de preprocessing
def advanced_preprocessing(df):
    # DÃ©tection outliers avec IQR
    Q1 = df.quantile(0.25)
    Q3 = df.quantile(0.75)
    IQR = Q3 - Q1
    outliers = (df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))
    
    # Imputation valeurs manquantes
    df_cleaned = df.fillna(df.median())
    
    # Feature scaling
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    df_scaled = scaler.fit_transform(df_cleaned)
    
    return df_scaled
```

### Tests Statistiques
- **Test de Shapiro-Wilk** : VÃ©rification normalitÃ© (p-value > 0.05)
- **Test de Levene** : HomogÃ©nÃ©itÃ© des variances
- **Test de Pearson** : CorrÃ©lations significatives (p < 0.05)
- **Test de Student** : Comparaisons de moyennes

### Validation CroisÃ©e
- **K-fold cross-validation** (k=5) pour validation robuste
- **Train/Test split** : 80%/20% avec stratification
- **Bootstrap sampling** : 1000 Ã©chantillons pour intervalles de confiance
- **MÃ©triques multiples** : MAE, RMSE, RÂ², AIC, BIC

## ğŸ“Š Visualisations RÃ©alisÃ©es

### Graphiques Exploratoires
- **Histogrammes** avec courbes de densitÃ©
- **Boxplots** pour dÃ©tection outliers
- **Scatter plots** avec droites de rÃ©gression
- **Pairplots** pour relations multivariÃ©es

### Analyses AvancÃ©es
- **Heatmaps de corrÃ©lation** avec clustering hiÃ©rarchique
- **Graphiques de rÃ©sidus** pour validation modÃ¨les
- **Courbes ROC** et mÃ©triques de classification
- **Graphiques de distribution** comparatives

### Visualisations Interactives
```python
import plotly.express as px
import plotly.graph_objects as go

# Exemple visualisation interactive
fig = px.scatter_3d(df, x='surface', y='prix', z='age',
                   color='quartier', size='nb_pieces',
                   title='Analyse 3D Prix Immobilier')
fig.show()
```

## ğŸ§® Techniques Statistiques AvancÃ©es

### RÃ©gression Multiple
- **SÃ©lection de variables** : Stepwise, LASSO, Ridge
- **Interactions** : Tests d'interactions entre variables
- **Polynomial features** : Termes quadratiques et cubiques
- **Validation modÃ¨les** : AIC, BIC, adjusted RÂ²

### Analyse de Variance
- **ANOVA one-way** : Comparaison groupes multiples
- **ANOVA two-way** : Effets principaux et interactions
- **ANCOVA** : Variables continue et catÃ©gorielle
- **Post-hoc tests** : Tukey HSD, Bonferroni

### Tests Non-ParamÃ©triques
- **Mann-Whitney U** : Comparaison 2 groupes indÃ©pendants
- **Kruskal-Wallis** : Alternative non-paramÃ©trique ANOVA
- **Spearman** : CorrÃ©lations monotones
- **Chi-carrÃ©** : IndÃ©pendance variables catÃ©gorielles

## ğŸ“ˆ RÃ©sultats et Insights

### Performance ModÃ¨les
| ModÃ¨le | Dataset | MÃ©trique | Score |
|--------|---------|----------|-------|
| **Linear Regression** | Immobilier | RÂ² | 0.847 |
| **Logistic Regression** | SantÃ© | Accuracy | 91.3% |
| **Random Forest** | Marketing | F1-score | 0.876 |
| **SVM** | Immobilier | RMSE | 12.8Kâ‚¬ |

### Insights MÃ©tier
- **Immobilier** : Surface et localisation expliquent 85% variance prix
- **Marketing** : Segmentation amÃ©liore ROI de 23% vs approche globale
- **SantÃ©** : 5 facteurs prÃ©disent 91% des risques cardiovasculaires

### Recommandations
- **Feature engineering** crucial pour performance modÃ¨les
- **Validation croisÃ©e** indispensable pour Ã©viter overfitting
- **InterpretabilitÃ©** vs performance : Ã©quilibre Ã  trouver
- **Domain knowledge** essentiel pour feature selection

## ğŸ› ï¸ Outils et Technologies

### Environnement Python
- **Jupyter Notebooks** : DÃ©veloppement interactif et prototypage
- **Pandas** : Manipulation et analyse de donnÃ©es tabulaires
- **NumPy** : Calculs numÃ©riques et algÃ¨bre linÃ©aire
- **SciPy** : Tests statistiques et optimisation

### Visualisation
- **Matplotlib** : Graphiques statiques publication-ready
- **Seaborn** : Visualisations statistiques Ã©lÃ©gantes
- **Plotly** : Graphiques interactifs et dashboards
- **Bokeh** : Visualisations web interactives

### Machine Learning
- **Scikit-learn** : ModÃ¨les ML et preprocessing
- **Statsmodels** : ModÃ¨les statistiques et tests
- **XGBoost** : Gradient boosting performance
- **Feature-engine** : Feature engineering automatisÃ©

## ğŸ“š CompÃ©tences DÃ©veloppÃ©es

### Techniques
- **Analyse exploratoire** systÃ©matique et rigoureuse
- **ModÃ©lisation statistique** avec validation appropriÃ©e
- **Visualisation** claire et informative
- **Interpretation** statistique et mÃ©tier des rÃ©sultats

### MÃ©thodologiques
- **DÃ©marche scientifique** : hypothÃ¨ses, tests, validation
- **PensÃ©e critique** : remise en question des rÃ©sultats
- **Communication** : prÃ©sentation insights aux non-experts
- **ReproductibilitÃ©** : code documentÃ© et versionnÃ©

## ğŸ¯ Applications Pratiques

### Secteur Immobilier
- **Estimation automatique** prix biens immobiliers
- **Identification** facteurs de valorisation
- **Optimisation** stratÃ©gies pricing agences

### Marketing Digital
- **Segmentation clientÃ¨le** data-driven
- **Optimisation** allocation budgets publicitaires
- **Personnalisation** campagnes marketing

### SantÃ© Publique
- **Screening** automatisÃ© populations Ã  risque
- **PrÃ©vention** ciblÃ©e facteurs modifiables
- **Optimisation** ressources sanitaires

---

*Travaux pratiques dÃ©montrant une maÃ®trise complÃ¨te des techniques de Data Science, de l'analyse exploratoire Ã  la modÃ©lisation prÃ©dictive avec validation rigoureuse.*
